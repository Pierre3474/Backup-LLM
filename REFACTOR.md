# Refactoring Architecture - Voicebot SAV Production-Ready

## üìã Vue d'ensemble

Ce document explique la nouvelle architecture modulaire du voicebot, con√ßue pour √™tre **maintenable, testable et production-ready**.

### Probl√®mes r√©solus

| Avant (Monolithe) | Apr√®s (Clean Architecture) |
|-------------------|----------------------------|
| 1 fichier de 1500+ lignes | Modules s√©par√©s ~200 lignes |
| If/elif imbriqu√©s pour √©tats | Machine √† √©tats d√©clarative |
| Prompts en dur dans le code | 100% externalis√©s dans YAML |
| Analyse par mots-cl√©s | LLM ‚Üí JSON structur√© |
| Endpointing fixe (500ms) | Dynamique selon contexte |
| Difficile √† tester | Modules ind√©pendants testables |

---

## üèóÔ∏è Architecture

```
voicebot_sav/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ settings.py          # Configuration centralis√©e (h√©rite config.py)
‚îÇ   ‚îî‚îÄ‚îÄ prompts.yaml          # Prompts externalis√©s + intents JSON
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ conversation.py       # ConversationContext, ConversationState, ClientInfo
‚îÇ   ‚îî‚îÄ‚îÄ intents.py            # Intent, IntentType, prompts JSON
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ stt.py                # STTService (Deepgram, endpointing dynamique)
‚îÇ   ‚îú‚îÄ‚îÄ llm.py                # LLMService (Groq, prompts, historique)
‚îÇ   ‚îú‚îÄ‚îÄ tts.py                # TTSService (ElevenLabs, streaming, cache)
‚îÇ   ‚îî‚îÄ‚îÄ database.py           # DatabaseService (wrapper db_utils)
‚îÇ
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ intent_analyzer.py    # IntentAnalyzer (LLM ‚Üí JSON)
‚îÇ   ‚îú‚îÄ‚îÄ state_machine.py      # StateMachine (transitions d√©claratives)
‚îÇ   ‚îî‚îÄ‚îÄ call_handler.py       # CallHandler (orchestrateur)
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ audio.py              # AudioCache (LRU dynamique)
‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py     # Logs structur√©s (JSON optionnel)
‚îÇ   ‚îî‚îÄ‚îÄ validation.py         # Validation email, phone, sentiment
‚îÇ
‚îî‚îÄ‚îÄ main.py                   # Point d'entr√©e (serveur AudioSocket)
```

---

## üéØ Concepts cl√©s

### 1. **Endpointing Dynamique (STT)**

Au lieu d'un endpointing fixe (500ms), le syst√®me adapte automatiquement :

```python
# R√©ponse oui/non ‚Üí 500ms (r√©actif)
stt_service.set_endpointing_mode("yes_no")

# R√©ponse ouverte ‚Üí 1200ms (laisse temps de r√©fl√©chir)
stt_service.set_endpointing_mode("open")
```

**Configuration** : `config/settings.py`
```python
STT_ENDPOINTING_MODES = {
    "open": 1200,      # Pour questions ouvertes
    "yes_no": 500,     # Pour confirmations
    "quick": 500       # Pour r√©ponses courtes
}
```

### 2. **Analyse d'Intention (LLM ‚Üí JSON)**

Au lieu de mots-cl√©s simples, le LLM retourne du JSON structur√© :

```python
# Ancien (mots-cl√©s)
if "oui" in user_text.lower():
    # Pas fiable si phrase complexe

# Nouveau (JSON structur√©)
intent = await intent_analyzer.analyze_yes_no(user_text, context)
# Intent {
#   "intent": "yes",
#   "confidence": 0.95,
#   "is_off_topic": false,
#   "requires_clarification": false
# }

if intent.is_yes():
    # Fiable m√™me avec phrase complexe
```

**Prompts** : `prompts.yaml` (section `INTENT_*`)

### 3. **Machine √† √âtats D√©clarative**

Au lieu de if/elif imbriqu√©s, transitions propres :

```python
# Ancien
if self.state == "VERIFICATION":
    if "oui" in text:
        self.state = "GOODBYE"
    else:
        self.state = "TRANSFER"

# Nouveau
state_machine.add_transition(
    StateTransition(
        from_state=ConversationState.VERIFICATION,
        to_state=ConversationState.GOODBYE,
        condition=lambda ctx, intent: intent.is_yes()
    )
)

new_state = await state_machine.process_intent(context, intent)
```

**Fichier** : `core/state_machine.py`

### 4. **Prompts 100% Externes**

Aucun prompt en dur dans le code Python :

```python
# Ancien
prompt = "Tu es un assistant vocal SAV. R√©ponds en 1-2 phrases..."

# Nouveau
prompt = llm_service.build_system_prompt(client_info, client_history)
# Charge depuis prompts.yaml avec variables dynamiques
```

**Configuration** : `prompts.yaml`

---

## üìö Guide d'utilisation des modules

### Services

#### STTService (Speech-to-Text)

```python
from services.stt import STTService

stt = STTService(call_id="abc123")

# Callback pour transcriptions
async def on_transcript(text: str, is_final: bool):
    if is_final:
        print(f"Transcription finale: {text}")

# D√©marrer
await stt.start(
    input_queue=audio_queue,
    on_transcript=on_transcript
)

# Changer mode dynamiquement
stt.set_endpointing_mode("yes_no")  # Court
stt.set_endpointing_mode("open")    # Long

# Arr√™ter proprement
await stt.stop()
```

#### LLMService (G√©n√©ration r√©ponses)

```python
from services.llm import LLMService

llm = LLMService(call_id="abc123")

# Construire prompt syst√®me
system_prompt = llm.build_system_prompt(
    client_info={"first_name": "Jean", "last_name": "Dupont"},
    client_history=[...]
)

# G√©n√©rer r√©ponse
response = await llm.generate_response(
    user_message="J'ai un probl√®me avec ma box",
    system_prompt=system_prompt,
    conversation_history=[
        {"role": "assistant", "content": "Bonjour..."},
        {"role": "user", "content": "Bonjour"}
    ]
)

# Analyse intention (retour JSON)
json_response = await llm.analyze_intent_json(
    user_message="Oui exactement",
    intent_prompt_template=INTENT_PROMPTS["yes_no"]
)
```

#### TTSService (Synth√®se vocale)

```python
from services.tts import TTSService
from utils.audio import AudioCache

cache = AudioCache()
tts = TTSService(call_id="abc123", audio_cache=cache)

# G√©n√©rer audio (streaming)
async for chunk in tts.generate_audio("Bonjour, comment puis-je vous aider ?"):
    # Envoyer chunk (320 bytes = 20ms) √† Asterisk
    await send_to_asterisk(chunk)

# R√©cup√©rer phrase pr√©-cach√©e
audio = tts.get_cached_phrase("welcome")
if audio:
    await send_to_asterisk(audio)
```

### Core

#### IntentAnalyzer

```python
from core.intent_analyzer import IntentAnalyzer
from models.conversation import ConversationContext

analyzer = IntentAnalyzer(call_id="abc123", llm_service=llm)
context = ConversationContext(call_id="abc123")

# Analyser oui/non
intent = await analyzer.analyze_yes_no("Oui c'est √ßa", context)
if intent.is_yes():
    print("Confirmation positive")

# Analyser type de probl√®me
intent = await analyzer.analyze_problem_type("Ma box ne marche plus")
if intent.intent_type == IntentType.INTERNET_ISSUE:
    print(f"Probl√®me internet d√©tect√© (confidence: {intent.confidence})")

# Analyser sentiment
needs_escalation = analyzer.analyze_sentiment("C'est inadmissible !", context)
if needs_escalation:
    print("Client en col√®re ‚Üí Transfert imm√©diat")
```

#### StateMachine

```python
from core.state_machine import StateMachine
from models.conversation import ConversationState

sm = StateMachine(call_id="abc123")

# Traiter une intention
new_state = await sm.process_intent(context, intent)

# Obtenir le mode STT appropri√©
stt_mode = sm.get_stt_mode_for_state(context.current_state)
# "yes_no" pour VERIFICATION, "open" pour DIAGNOSTIC

# V√©rifier les intentions attendues
expected = sm.get_expected_intent_types(ConversationState.VERIFICATION)
# [IntentType.YES, IntentType.NO]
```

---

## üîÑ Migration progressive

### √âtape 1 : Utiliser les nouveaux services sans modifier server.py

```python
# Dans server.py existant, remplacer progressivement:

# Ancien
self.deepgram_client = DeepgramClient(config.DEEPGRAM_API_KEY)

# Nouveau
from services.stt import STTService
self.stt_service = STTService(self.call_id)
```

### √âtape 2 : Adopter l'analyse d'intention

```python
# Ancien
if "oui" in user_text.lower():
    ...

# Nouveau
from core.intent_analyzer import IntentAnalyzer
intent = await self.intent_analyzer.analyze_yes_no(user_text, self.context)
if intent.is_yes():
    ...
```

### √âtape 3 : Utiliser la state machine

```python
# Ancien
if self.state == "VERIFICATION":
    if "oui" in text:
        self.state = "GOODBYE"

# Nouveau
new_state = await self.state_machine.process_intent(self.context, intent)
if new_state:
    self.context.transition_to(new_state)
```

---

## üß™ Tests

L'architecture modulaire facilite les tests unitaires :

```python
# tests/test_intent_analyzer.py
import pytest
from core.intent_analyzer import IntentAnalyzer

@pytest.mark.asyncio
async def test_yes_analysis():
    analyzer = IntentAnalyzer("test", mock_llm_service)
    intent = await analyzer.analyze_yes_no("Oui c'est √ßa", mock_context)

    assert intent.is_yes()
    assert intent.confidence > 0.8
```

---

## üìä Avantages de la nouvelle architecture

### 1. **Maintenabilit√©**
- Chaque module a une responsabilit√© unique
- Facile de modifier un service sans casser le reste
- Prompts externalis√©s = modifications sans red√©ploiement code

### 2. **Testabilit√©**
- Services ind√©pendants facilement mockables
- Tests unitaires par module
- State machine testable sans API externes

### 3. **Extensibilit√©**
- Ajouter un nouveau service (ex: Sentiment Analysis) = cr√©er un fichier
- Nouveaux √©tats = ajouter transitions dans state_machine
- Nouveaux intents = ajouter dans models/intents.py

### 4. **Performance**
- Endpointing dynamique r√©duit latence per√ßue
- Cache audio LRU optimis√©
- Logging structur√© pour monitoring

### 5. **Debugging**
- Logs structur√©s avec call_id automatique
- Intents avec reasoning pour comprendre d√©cisions LLM
- State transitions trac√©es proprement

---

## ‚öôÔ∏è Configuration

### Variables d'environnement (ajouts)

```bash
# Endpointing STT dynamique
STT_ENDPOINTING_DEFAULT=1200
STT_ENDPOINTING_SHORT=500

# Intent analysis
INTENT_ANALYSIS_MODEL=llama-3.3-70b-versatile
SENTIMENT_ANGER_THRESHOLD=3

# Cache
DYNAMIC_CACHE_MAX_SIZE=50

# Logging
STRUCTURED_LOGGING=true
LOG_FORMAT_JSON=false
```

### Fichiers de configuration

- `config/settings.py` : H√©rite et √©tend `config.py`
- `prompts.yaml` : Tous les prompts syst√®me et intents
- `.env` : Variables sensibles (API keys)

---

## üöÄ Prochaines √©tapes

### Phase 1 : Migration server.py ‚Üí CallHandler
- [ ] Cr√©er `core/call_handler.py` utilisant les nouveaux services
- [ ] Migrer logique √©tat par √©tat
- [ ] Tests de non-r√©gression

### Phase 2 : Optimisations
- [ ] Impl√©menter retry automatique sur erreurs API
- [ ] M√©triques Prometheus d√©taill√©es par service
- [ ] Circuit breaker pour services externes

### Phase 3 : Fonctionnalit√©s avanc√©es
- [ ] Multi-langues via configuration
- [ ] A/B testing de prompts
- [ ] ML pour pr√©diction escalade

---

## üìñ R√©f√©rences

- Architecture: Clean Architecture (Uncle Bob)
- Patterns: State Machine, Strategy, Dependency Injection
- Logs: Structured Logging (12 Factor App)

---

**Auteur**: Refactoring Architecture
**Date**: 2025-12-23
**Version**: 1.0.0
