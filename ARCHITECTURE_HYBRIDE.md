# ğŸš€ Architecture Hybride - Masquage de Latence

## Vue d'ensemble

L'architecture hybride du voicebot SAV combine **phrases en cache** (rÃ©ponse instantanÃ©e 0ms) avec **gÃ©nÃ©ration IA personnalisÃ©e** pour masquer complÃ¨tement la latence perÃ§ue par le client.

## Principe

```
AVANT (Architecture sÃ©quentielle):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client dit  â”‚ â”€â”€â–¶ â”‚ Attente 2-3s...  â”‚ â”€â”€â–¶ â”‚ Bot rÃ©pond  â”‚
â”‚ son problÃ¨meâ”‚     â”‚ (gÃ©nÃ©ration LLM) â”‚     â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    âš ï¸ SILENCE GÃŠNANT

APRÃˆS (Architecture hybride):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client dit  â”‚ â”€â”€â–¶ â”‚ Filler CACHE â”‚ â”€â”€â–¶ â”‚ GÃ©nÃ©ration LLM  â”‚ â”€â”€â–¶ â”‚ RÃ©ponse IA   â”‚
â”‚ son problÃ¨meâ”‚     â”‚ "Hum..."     â”‚     â”‚ en arriÃ¨re-plan â”‚     â”‚ personnalisÃ©eâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    âœ… 0ms latence      MasquÃ©e par filler
```

## Fonctionnement technique

### 1. Fonction `_say_hybrid(cache_key, personalized_text)`

```python
async def _say_hybrid(self, cache_key: str, personalized_text: str):
    # 1. Lance gÃ©nÃ©ration en arriÃ¨re-plan (Task asynchrone)
    generation_task = asyncio.create_task(self._generate_audio(personalized_text))

    # 2. Joue cache IMMÃ‰DIATEMENT (0ms)
    await self._say(cache_key)

    # 3. Attend fin gÃ©nÃ©ration (masquÃ©e par cache)
    await generation_task
```

**Workflow:**
- **T+0ms**: Client entend la phrase cache instantanÃ©ment
- **T+0-2000ms**: GÃ©nÃ©ration IA en cours (invisible pour le client)
- **T+2000ms**: Phrase personnalisÃ©e prÃªte et jouÃ©e

### 2. Fillers intelligents (phrases cache courtes)

Nouveaux fillers ajoutÃ©s dans `config.py`:
```python
"filler_hum": "Hum, laissez-moi regarder...",
"filler_ok": "TrÃ¨s bien, je note...",
"filler_one_moment": "Un instant s'il vous plaÃ®t...",
"filler_let_me_see": "Laissez-moi voir Ã§a...",
```

**Utilisation dans DIAGNOSTIC:**
```python
# AVANT dÃ©tection de problÃ¨me (qui prend 200-500ms)
filler_phrases = ["filler_hum", "filler_ok", "filler_let_me_see"]
await self._say(random.choice(filler_phrases))

# Pendant que filler joue, dÃ©tection en cours
problem_type = self._detect_problem_type(user_text)
```

### 3. Accueil personnalisÃ© (cas client connu)

**AVANT:**
```python
await self._say("greet")              # 3s d'attente
await self._say_smart("M. Dupont...")  # 2s gÃ©nÃ©ration
await self._say("welcome")            # SÃ©quentiel
```

**APRÃˆS (Hybride):**
```python
await self._say_hybrid(
    "greet",  # JouÃ© instantanÃ©ment
    f"Monsieur {last_name}, je vois votre ticket"  # GÃ©nÃ©rÃ© pendant
)
# Client entend "Bonjour" immÃ©diatement, puis phrase personnalisÃ©e
```

### 4. FÃ©licitation personnalisÃ©e (VERIFICATION)

Quand le client confirme que Ã§a marche:
```python
# GÃ©nÃ¨re fÃ©licitation courte avec LLM
congratulation_prompt = (
    f"Le client {first_name} a rÃ©solu son problÃ¨me. "
    f"GÃ©nÃ¨re UNE phrase courte (max 10 mots) pour le fÃ©liciter."
)
congratulation = await self._ask_llm("", congratulation_prompt)

# HYBRIDE: Filler + fÃ©licitation
await self._say_hybrid("filler_ok", congratulation)
# â†’ "TrÃ¨s bien, je note... Bravo Pierre, excellent travail !"
```

## Optimisations modÃ¨les IA

### ElevenLabs TTS
- **ModÃ¨le:** `eleven_turbo_v2_5` (dÃ©jÃ  configurÃ©)
- **Latence:** <300ms
- **CoÃ»t:** -50% vs modÃ¨le standard

### Groq LLM
- **ModÃ¨le:** `llama-3.3-70b-versatile`
- **Performance:** ~500-1000ms pour rÃ©ponses courtes
- **TempÃ©rature:** 0.7 (Ã©quilibre crÃ©ativitÃ©/cohÃ©rence)

## Impact utilisateur

### Gains de rÃ©activitÃ©

| Ã‰tape              | AVANT (sÃ©quentiel) | APRÃˆS (hybride) | Gain     |
|--------------------|--------------------|-----------------|----------|
| Accueil client     | 0-3s silence       | 0ms (cache)     | **100%** |
| Diagnostic         | 0-2s silence       | 0ms (filler)    | **100%** |
| FÃ©licitation       | GÃ©nÃ©rique          | PersonnalisÃ©e   | **+UX**  |

### ExpÃ©rience perÃ§ue

**AVANT:**
```
Client: "Ma box internet ne marche pas"
[2s de silence...]
Bot: "D'accord, essayez de redÃ©marrer..."
```
âš ï¸ Silence = impression de lenteur/bug

**APRÃˆS:**
```
Client: "Ma box internet ne marche pas"
Bot: "Hum, laissez-moi regarder..." (instantanÃ©)
[Bot analyse pendant que phrase joue]
Bot: "D'accord, essayez de redÃ©marrer..."
```
âœ… Aucun silence = impression de rapiditÃ©

## GÃ©nÃ©ration cache audio

Les nouveaux fillers doivent Ãªtre prÃ©-gÃ©nÃ©rÃ©s en 8kHz:

```bash
cd /opt/PY_SAV
python3 generate_cache.py
```

Le script lit automatiquement `config.CACHED_PHRASES` et gÃ©nÃ¨re les fichiers `.raw` manquants.

## MÃ©triques de performance

L'architecture hybride permet de tracker :
- **Cache hit rate** (phrases jouÃ©es depuis cache vs gÃ©nÃ©ration)
- **Temps de rÃ©ponse TTS** (cache ~1ms vs API ~300-2000ms)
- **CoÃ»ts API** (rÃ©duction 60-80% via cache intelligent)

Voir `metrics.py` pour le tracking Prometheus.

## Exemples d'utilisation

### Client nouveau (100% cache)
```python
await self._say("greet")     # Cache
await self._say("welcome")   # Cache
# 0 appel API, latence 0ms
```

### Client connu (Hybride)
```python
await self._say_hybrid(
    "greet",  # Cache jouÃ© instantanÃ©ment
    f"{first_name} {last_name}, comment puis-je vous aider ?"
)
# 1 appel API, latence perÃ§ue 0ms (masquÃ©e par cache)
```

### Diagnostic (Filler intelligent)
```python
await self._say(random.choice(filler_phrases))  # Cache
problem_type = self._detect_problem_type(text)  # Analyse masquÃ©e
```

## Conclusion

L'architecture hybride transforme l'expÃ©rience utilisateur en **Ã©liminant les silences gÃªnants** tout en conservant la **personnalisation IA**. Le client ne perÃ§oit plus aucune latence, le bot semble instantanÃ© et humain.

**RÃ©sultat:** Bot perÃ§u comme **rÃ©actif, professionnel et personnalisÃ©** au lieu de **lent et robotique**.
